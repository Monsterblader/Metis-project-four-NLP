{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 5.07 ms\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tools.functions\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 241 µs\n"
     ]
    }
   ],
   "source": [
    "vectorizer_max_features = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 6.32 s\n"
     ]
    }
   ],
   "source": [
    "all_text = pd.read_csv('archive/sub_reddits.csv')\n",
    "all_text['selftext'] = all_text['selftext'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "sanitized_posts_df = pd.DataFrame(tools.functions.sanitize_posts(all_text['selftext']), columns=['posts'])\n",
    "sanitized_posts_df = sanitized_posts_df[sanitized_posts_df['posts'] != '']\n",
    "sanitized_posts_df = sanitized_posts_df[sanitized_posts_df['posts'] != 'a']\n",
    "sanitized_posts_df = sanitized_posts_df[sanitized_posts_df['posts'] != '_']\n",
    "sanitized_posts_df = sanitized_posts_df[sanitized_posts_df['posts'].str.contains('[^\\d^\\s]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 703 µs\n"
     ]
    }
   ],
   "source": [
    "# Workspace for additional text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was this wrong?  I should only be running vectorizer.fit?\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "\n",
    "tfidfvectorized_posts = vectorizer.fit_transform(sanitized_posts_df['posts'])\n",
    ".toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "count_vectorized_posts = count_vectorizer.fit_transform(sanitized_posts_df['posts'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "tfidf = vectorizer.fit(sanitized_posts_df['posts'])\n",
    "tfidf_transformed = vectorizer.transform(sanitized_posts_df['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 22 s\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "tfidf_df = pd.DataFrame(tfidf_transformed.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    00      000  0000  00000  000000  000001  00001  0001  0001104659  \\\n",
       "0  0.0  0.00000   0.0    0.0     0.0     0.0    0.0   0.0         0.0   \n",
       "1  0.0  0.12075   0.0    0.0     0.0     0.0    0.0   0.0         0.0   \n",
       "2  0.0  0.00000   0.0    0.0     0.0     0.0    0.0   0.0         0.0   \n",
       "3  0.0  0.00000   0.0    0.0     0.0     0.0    0.0   0.0         0.0   \n",
       "4  0.0  0.00000   0.0    0.0     0.0     0.0    0.0   0.0         0.0   \n",
       "\n",
       "   0001193125  ...   то  уоu  что  это  ісо  الاستثمار   في  كما   من  \\\n",
       "0         0.0  ...  0.0  0.0  0.0  0.0  0.0        0.0  0.0  0.0  0.0   \n",
       "1         0.0  ...  0.0  0.0  0.0  0.0  0.0        0.0  0.0  0.0  0.0   \n",
       "2         0.0  ...  0.0  0.0  0.0  0.0  0.0        0.0  0.0  0.0  0.0   \n",
       "3         0.0  ...  0.0  0.0  0.0  0.0  0.0        0.0  0.0  0.0  0.0   \n",
       "4         0.0  ...  0.0  0.0  0.0  0.0  0.0        0.0  0.0  0.0  0.0   \n",
       "\n",
       "   ﬁnancial  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "\n",
       "[5 rows x 44890 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00</th>\n      <th>000</th>\n      <th>0000</th>\n      <th>00000</th>\n      <th>000000</th>\n      <th>000001</th>\n      <th>00001</th>\n      <th>0001</th>\n      <th>0001104659</th>\n      <th>0001193125</th>\n      <th>...</th>\n      <th>то</th>\n      <th>уоu</th>\n      <th>что</th>\n      <th>это</th>\n      <th>ісо</th>\n      <th>الاستثمار</th>\n      <th>في</th>\n      <th>كما</th>\n      <th>من</th>\n      <th>ﬁnancial</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.12075</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 44890 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 60.5 ms\n"
     ]
    }
   ],
   "source": [
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.13418152 0.11829433]\n0.25247584468078477\n[3170.21868301 2869.74127917]\ntime: 4.95 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=2, n_iter=7, random_state=42)\n",
    "svd.fit(count_vectorized_posts)\n",
    "\n",
    "\n",
    "print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "print(svd.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                00    000  0000  00000  000000  000001  00001  0001  \\\n",
       "component_1  0.037  0.024   0.0    0.0     0.0     0.0    0.0   0.0   \n",
       "component_2 -0.012 -0.005  -0.0   -0.0    -0.0    -0.0   -0.0  -0.0   \n",
       "\n",
       "             0001104659  0001193125  ...   то  уоu  что  это  ісо  الاستثمار  \\\n",
       "component_1         0.0         0.0  ...  0.0  0.0  0.0  0.0  0.0        0.0   \n",
       "component_2        -0.0        -0.0  ... -0.0 -0.0 -0.0 -0.0 -0.0       -0.0   \n",
       "\n",
       "              في  كما   من  ﬁnancial  \n",
       "component_1  0.0  0.0  0.0       0.0  \n",
       "component_2 -0.0 -0.0 -0.0      -0.0  \n",
       "\n",
       "[2 rows x 44890 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00</th>\n      <th>000</th>\n      <th>0000</th>\n      <th>00000</th>\n      <th>000000</th>\n      <th>000001</th>\n      <th>00001</th>\n      <th>0001</th>\n      <th>0001104659</th>\n      <th>0001193125</th>\n      <th>...</th>\n      <th>то</th>\n      <th>уоu</th>\n      <th>что</th>\n      <th>это</th>\n      <th>ісо</th>\n      <th>الاستثمار</th>\n      <th>في</th>\n      <th>كما</th>\n      <th>من</th>\n      <th>ﬁnancial</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>component_1</th>\n      <td>0.037</td>\n      <td>0.024</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>component_2</th>\n      <td>-0.012</td>\n      <td>-0.005</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>...</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n      <td>-0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 44890 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 63.8 ms\n"
     ]
    }
   ],
   "source": [
    "topic_word = pd.DataFrame(svd.components_.round(3), index=[\"component_1\", \"component_2\"], columns=vectorizer.get_feature_names())\n",
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time: 478 µs\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTopic  0\namp, http, com, gt, earnings\n\nTopic  1\ncomment, wallstreetbets, 17, 15, spy\ntime: 37.7 ms\n"
     ]
    }
   ],
   "source": [
    "display_topics(svd, vectorizer.get_feature_names(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=TfidfVectorizer(max_df=0.7, min_df=5,\n                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n                            'itself', ...]).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-22d58dfb8e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# for TFIDF DTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlda_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlda_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \"\"\"\n\u001b[1;32m    555\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         X = self._check_non_neg_array(X, reset_n_features=True,\n\u001b[0m\u001b[1;32m    557\u001b[0m                                       whom=\"LatentDirichletAllocation.fit\")\n\u001b[1;32m    558\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36m_check_non_neg_array\u001b[0;34m(self, X, reset_n_features, whom)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \"\"\"\n\u001b[0;32m--> 482\u001b[0;31m         X = self._validate_data(X, reset=reset_n_features,\n\u001b[0m\u001b[1;32m    483\u001b[0m                                 accept_sparse='csr')\n\u001b[1;32m    484\u001b[0m         \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;31m# If input is scalar raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    613\u001b[0m                     \u001b[0;34m\"Expected 2D array, got scalar array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=TfidfVectorizer(max_df=0.7, min_df=5,\n                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n                            'itself', ...]).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# for TF DTM\n",
    "# lda_tf = LatentDirichletAllocation(n_components=20, random_state=0)\n",
    "# lda_tf.fit(tfidfvectorized_posts)\n",
    "\n",
    "# for TFIDF DTM\n",
    "lda_tfidf = LatentDirichletAllocation(n_components=20, random_state=0)\n",
    "lda_tfidf.fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('archive/lda.20.0.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(lda_tfidf, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('archive/lda.20.0.pkl', 'rb') as picklefile:\n",
    "    lda_tfidf = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_lda = lda_tfidf.transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "pyLDAvis.sklearn.prepare(lda_tfidf, tfidfvectorized_posts, TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('metis': conda)",
   "display_name": "Python 3.8.5 64-bit ('metis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1a0499c7a4a50afe9d0222578684e6b7d0a5b28e1d6168b6dad088fd14a794c9"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}